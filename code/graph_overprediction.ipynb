{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1b1b80",
   "metadata": {},
   "source": [
    "# 1.Graph prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc58db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "\n",
    "from PIL import Image\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "\n",
    "# load Mask2Former fine-tuned on Cityscapes panoptic segmentation\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-tiny-cityscapes-panoptic\")\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-tiny-cityscapes-panoptic\")\n",
    "\n",
    "# load Mask2Former fine-tuned on Cityscapes panoptic segmentation\n",
    "# processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-small-cityscapes-panoptic\")\n",
    "# model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-small-cityscapes-panoptic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718690c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids_mapping = {\n",
    "    255: \"ego vehicle\",\n",
    "    255: \"rectification border\",\n",
    "    255: \"out of roi\",\n",
    "    255: \"static\",\n",
    "    255: \"dynamic\",\n",
    "    255: \"ground\",\n",
    "    0: \"road\",\n",
    "    1: \"sidewalk\",\n",
    "    255: \"parking\",\n",
    "    255: \"rail track\",\n",
    "    2: \"building\",\n",
    "    3: \"wall\",\n",
    "    4: \"fence\",\n",
    "    255: \"guard rail\",\n",
    "    255: \"bridge\",\n",
    "    255: \"tunnel\",\n",
    "    5: \"pole\",\n",
    "    255: \"polegroup\",\n",
    "    6: \"traffic light\",\n",
    "    7: \"traffic sign\",\n",
    "    8: \"vegetation\",\n",
    "    9: \"terrain\",\n",
    "    10: \"sky\",\n",
    "    11: \"person\",\n",
    "    12: \"rider\",\n",
    "    13: \"car\",\n",
    "    14: \"truck\",\n",
    "    15: \"bus\",\n",
    "    255: \"caravan\",\n",
    "    255: \"trailer\",\n",
    "    16: \"train\",\n",
    "    17: \"motorcycle\",\n",
    "    18: \"bicycle\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e00cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全景分割，获得每个mask\n",
    "def get_prediction(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)        \n",
    "    result = processor.post_process_instance_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    return result\n",
    "\n",
    "def label_to_onehot(label_id, num_classes=19):\n",
    "    # 创建一个所有元素都是0的向量\n",
    "    one_hot = np.zeros(num_classes, dtype=np.float32)\n",
    "    # 在对应的类别位置上置为1\n",
    "    one_hot[label_id] = 1.0\n",
    "    return one_hot\n",
    "\n",
    "# 求取每个mask的中心位置\n",
    "def get_mask_center(mask):\n",
    "    ys, xs = np.where(mask)\n",
    "    center = np.mean(xs), np.mean(ys)\n",
    "    return center\n",
    "\n",
    "# 求取每个mask的视觉比例\n",
    "def get_mask_area(mask, masks_panoptic):\n",
    "    total_pixels = len(masks_panoptic[0]) * len(masks_panoptic[1])\n",
    "    proportion = mask.sum() / total_pixels\n",
    "    return proportion\n",
    "\n",
    "# 将mask的边缘进行拓展，用于检测mask的邻接关系\n",
    "def expand_mask(mask):\n",
    "    expanded_mask = np.pad(mask, pad_width=1, mode='constant')\n",
    "    expanded_mask = np.logical_or.reduce([\n",
    "        expanded_mask[:-2, :-2],\n",
    "        expanded_mask[:-2, 1:-1],\n",
    "        expanded_mask[:-2, 2:],\n",
    "        expanded_mask[1:-1, :-2],\n",
    "        expanded_mask[1:-1, 2:],\n",
    "        expanded_mask[2:, :-2],\n",
    "        expanded_mask[2:, 1:-1],\n",
    "        expanded_mask[2:, 2:]\n",
    "    ])\n",
    "    return expanded_mask\n",
    "\n",
    "# 创建图结构\n",
    "def create_graph(image_path):\n",
    "    results = get_prediction(image_path)\n",
    "    masks_panoptic = results[\"segmentation\"].numpy()\n",
    "    label_ids = [item[\"label_id\"] for item in results[\"segments_info\"]]\n",
    "    num_classes = 19\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for i, class_id in enumerate(np.unique(masks_panoptic)[1:]):\n",
    "        class_mask = (masks_panoptic == class_id)\n",
    "        adj = expand_mask(class_mask)\n",
    "        # 获得mask的中心位置\n",
    "        center = get_mask_center(class_mask)\n",
    "        # 获得mask的视觉比例\n",
    "        proportions = get_mask_area(class_mask, masks_panoptic)\n",
    "        # 获取mask的类别\n",
    "        # label_name = label_ids_mapping.get(label_ids[i])\n",
    "        label_name = label_ids[i]\n",
    "        # label_onehot = onehot_encoder.transform([[label_name]]).squeeze(0)\n",
    "        one_hot_label = label_to_onehot(label_ids[i], num_classes=num_classes)\n",
    "\n",
    "        # 将属性添加到节点中\n",
    "        G.add_node(i, label_id=label_name,\n",
    "                   label_class=one_hot_label, \n",
    "                   mask_center=center, \n",
    "                   mask_proportions=proportions, \n",
    "                   mask_adj=adj\n",
    "                   )  \n",
    "    # 构建边\n",
    "    for i in range(len(G.nodes)):\n",
    "        for j in range(i + 1, len(G.nodes)):\n",
    "            mask_i = G.nodes[i]['mask_adj']\n",
    "            mask_j = G.nodes[j]['mask_adj']\n",
    "            if np.any(np.logical_and(mask_i, mask_j)):\n",
    "                G.add_edge(i, j)\n",
    "    return G\n",
    "\n",
    "def networkx_to_pyg(G):\n",
    "    mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "    # mapping = {node: G.nodes[node]['label_id'] for i, node in enumerate(G.nodes())}\n",
    "    edges_remap = [(mapping[u], mapping[v]) for u, v in G.edges()]\n",
    "    edge_index = torch.tensor(list(zip(*edges_remap)), dtype=torch.long).contiguous()\n",
    "    \n",
    "    x = torch.cat([torch.tensor([G.nodes[node]['mask_proportions'] for node in G.nodes()], dtype=torch.float).reshape(-1, 1),\n",
    "                   torch.tensor([G.nodes[node]['label_class'] for node in G.nodes()], dtype=torch.float)], dim=1)\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    return data\n",
    "\n",
    "class MyGraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, image_paths, labels, transform=None, pre_transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.root = root\n",
    "        self.force_processing = True\n",
    "        super(MyGraphDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # Since we're getting raw images paths, we don't care about raw files.\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        if os.path.exists(self.processed_paths[0]):\n",
    "            os.remove(self.processed_paths[0])\n",
    "\n",
    "        data_list = []\n",
    "        for i, image_path in enumerate(self.image_paths):\n",
    "            G = create_graph(image_path)\n",
    "            \n",
    "            if G.number_of_edges() > 0:\n",
    "                data = networkx_to_pyg(G)\n",
    "                data.y = torch.tensor([self.labels[i]], dtype=torch.long)\n",
    "                data_list.append(data)\n",
    "        \n",
    "        # Use the collate function of InMemoryDataset to properly combine the list of Data objects\n",
    "        data, slices = self.collate(data_list)\n",
    "\n",
    "        # Save the newly processed data for future loads\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a2fc7",
   "metadata": {},
   "source": [
    "# 2.Load data & Creat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# 获取文件夹内所有图像的path+名称\n",
    "folder_path = \"E:/Dataset/project_dataset/GNN_Perception/wuhan_badu_SVI/test\"\n",
    "\n",
    "image_paths = glob(os.path.join(folder_path, '*.*'))\n",
    "\n",
    "# 创建 DataFrame\n",
    "df = pd.DataFrame({'path': image_paths})\n",
    "\n",
    "csv_file = 'F:/桌面/depth/image_paths.csv' \n",
    "df.to_csv(csv_file, index=False)  # 设置 index=False 以避免写入行索引到 CSV 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e5f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_11852\\764652395.py:87: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = torch.cat([torch.tensor([G.nodes[node]['mask_proportions'] for node in G.nodes()], dtype=np.float).reshape(-1, 1),\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_11852\\764652395.py:88: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  torch.tensor([G.nodes[node]['label_class'] for node in G.nodes()], dtype=np.float)], dim=1)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# proccess后的文件\n",
    "root_dir = 'E:/Datase/xxxx/test2'\n",
    "\n",
    "# 加载文件，包含path和label*\n",
    "img_name = pd.read_csv(\"F:/桌面/depth/image_paths.csv\", encoding='GBK')\n",
    "\n",
    "image_paths = img_name['path']\n",
    "labels = img_name['label']\n",
    "\n",
    "dataset = MyGraphDataset(root=root_dir, image_paths=image_paths, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc30b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyGraphDataset (#graphs=13):\n",
       "+------------+----------+----------+\n",
       "|            |   #nodes |   #edges |\n",
       "|------------+----------+----------|\n",
       "| mean       |     16.6 |     29.1 |\n",
       "| std        |     13.3 |     28.5 |\n",
       "| min        |      4   |      4   |\n",
       "| quantile25 |      6   |      6   |\n",
       "| median     |     11   |     19   |\n",
       "| quantile75 |     30   |     56   |\n",
       "| max        |     38   |     78   |\n",
       "+------------+----------+----------+"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "839c8067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.data.in_memory_dataset.InMemoryDataset"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.datasets as datasets\n",
    "\n",
    "InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63563ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MyGraphDataset(13):\n",
      "====================\n",
      "Number of graphs: 13\n",
      "Number of features: 20\n",
      "Number of classes: 3\n",
      "\n",
      "Data(x=[11, 20], edge_index=[2, 21], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 11\n",
      "Number of edges: 21\n",
      "Average node degree: 1.91\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "# 查看生成的图数据集\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412d190",
   "metadata": {},
   "source": [
    "# 3.Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d02c5073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 11\n",
      "Number of test graphs: 2\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:11]\n",
    "test_dataset = dataset[11:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab9a1e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[9, 20], edge_index=[2, 8], y=[1], batch=[9], ptr=[2])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[10, 20], edge_index=[2, 15], y=[1], batch=[10], ptr=[2])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[12, 20], edge_index=[2, 21], y=[1], batch=[12], ptr=[2])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[35, 20], edge_index=[2, 56], y=[1], batch=[35], ptr=[2])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[38, 20], edge_index=[2, 78], y=[1], batch=[38], ptr=[2])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[4, 20], edge_index=[2, 4], y=[1], batch=[4], ptr=[2])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[38, 20], edge_index=[2, 76], y=[1], batch=[38], ptr=[2])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[6, 20], edge_index=[2, 5], y=[1], batch=[6], ptr=[2])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[12, 20], edge_index=[2, 19], y=[1], batch=[12], ptr=[2])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[6, 20], edge_index=[2, 5], y=[1], batch=[6], ptr=[2])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 1\n",
      "DataBatch(x=[30, 20], edge_index=[2, 64], y=[1], batch=[30], ptr=[2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a179e48",
   "metadata": {},
   "source": [
    "# 4.Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ceb6951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(20, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183da2f9",
   "metadata": {},
   "source": [
    "# 5.Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15a1de5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.4545, Test Acc: 1.0000\n",
      "Epoch: 002, Train Acc: 0.6364, Test Acc: 0.5000\n",
      "Epoch: 003, Train Acc: 0.7273, Test Acc: 0.0000\n",
      "Epoch: 004, Train Acc: 0.6364, Test Acc: 0.0000\n",
      "Epoch: 005, Train Acc: 0.7273, Test Acc: 0.0000\n",
      "Epoch: 006, Train Acc: 0.6364, Test Acc: 0.0000\n",
      "Epoch: 007, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 008, Train Acc: 0.6364, Test Acc: 0.0000\n",
      "Epoch: 009, Train Acc: 0.6364, Test Acc: 0.0000\n",
      "Epoch: 010, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 011, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 012, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 013, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 014, Train Acc: 0.8182, Test Acc: 0.0000\n",
      "Epoch: 015, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 016, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 017, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 018, Train Acc: 0.9091, Test Acc: 0.0000\n",
      "Epoch: 019, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 020, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 021, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 022, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 023, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 024, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 025, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 026, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 027, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 028, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 029, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 030, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 031, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 032, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 033, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 034, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 035, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 036, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 037, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 038, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 039, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 040, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 041, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 042, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 043, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 044, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 045, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 046, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 047, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 048, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 049, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 050, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 051, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 052, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 053, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 054, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 055, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 056, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 057, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 058, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 059, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 060, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 061, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 062, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 063, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 064, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 065, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 066, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 067, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 068, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 069, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 070, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 071, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 072, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 073, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 074, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 075, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 076, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 077, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 078, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 079, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 080, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 081, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 082, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 083, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 084, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 085, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 086, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 087, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 088, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 089, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 090, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 091, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 092, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 093, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 094, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 095, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 096, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 097, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 098, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 099, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 100, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 101, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 102, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 103, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 104, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 105, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 106, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 107, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 108, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 109, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 110, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 111, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 112, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 113, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 114, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 115, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 116, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 117, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 118, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 119, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 120, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 121, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 122, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 123, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 124, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 125, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 126, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 127, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 128, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 129, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 130, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 131, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 132, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 133, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 134, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 135, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 136, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 137, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 138, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 139, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 140, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 141, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 142, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 143, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 144, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 145, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 146, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 147, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 148, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 149, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 150, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 151, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 152, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 153, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 154, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 155, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 156, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 157, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 158, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 159, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 160, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 161, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 162, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 163, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 164, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 165, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 166, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 167, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 168, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 169, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 170, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 171, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 172, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 173, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 174, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 175, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 176, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 177, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 178, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 179, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 180, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 181, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 182, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 183, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 184, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 185, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 186, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 187, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 188, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 189, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 190, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 191, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 192, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 193, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 194, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 195, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 196, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 197, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 198, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 199, Train Acc: 1.0000, Test Acc: 0.0000\n",
      "Epoch: 200, Train Acc: 1.0000, Test Acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccba3ed",
   "metadata": {},
   "source": [
    "# 6.Single graph visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"F:/桌面/depth/20231225152851.png\"\n",
    "\n",
    "G = create_graph(img)\n",
    "\n",
    "pos = {i: G.nodes[i]['mask_center'] for i in G.nodes()}\n",
    "labels = {i: G.nodes[i]['label_id'] for i in G.nodes()}\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "pos = nx.spring_layout(G, iterations=10)\n",
    "nx.draw(G, pos, labels=labels, with_labels=True, node_size=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991de2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seg = get_prediction(img)[\"segmentation\"].numpy()\n",
    "color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "palette = np.array(ade_palette())\n",
    "for label, color in enumerate(palette):\n",
    "    color_seg[seg == label, :] = color\n",
    "# Convert to BGR\n",
    "color_seg = color_seg[..., ::-1]\n",
    "\n",
    "# Show image + mask\n",
    "img = np.array(image) * 0.1 + color_seg * 0.9\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ade_palette():\n",
    "    \"\"\"ADE20K palette that maps each class to RGB values.\"\"\"\n",
    "    return [[120, 120, 120], [180, 120, 120], [6, 230, 230], [80, 50, 50],\n",
    "            [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255],\n",
    "            [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7],\n",
    "            [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82],\n",
    "            [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3],\n",
    "            [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255],\n",
    "            [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220],\n",
    "            [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224],\n",
    "            [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255],\n",
    "            [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7],\n",
    "            [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153],\n",
    "            [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255],\n",
    "            [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0],\n",
    "            [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255],\n",
    "            [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255],\n",
    "            [11, 200, 200], [255, 82, 0], [0, 255, 245], [0, 61, 255],\n",
    "            [0, 255, 112], [0, 255, 133], [255, 0, 0], [255, 163, 0],\n",
    "            [255, 102, 0], [194, 255, 0], [0, 143, 255], [51, 255, 0],\n",
    "            [0, 82, 255], [0, 255, 41], [0, 255, 173], [10, 0, 255],\n",
    "            [173, 255, 0], [0, 255, 153], [255, 92, 0], [255, 0, 255],\n",
    "            [255, 0, 245], [255, 0, 102], [255, 173, 0], [255, 0, 20],\n",
    "            [255, 184, 184], [0, 31, 255], [0, 255, 61], [0, 71, 255],\n",
    "            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],\n",
    "            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],\n",
    "            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],\n",
    "            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],\n",
    "            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],\n",
    "            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],\n",
    "            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],\n",
    "            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],\n",
    "            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],\n",
    "            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],\n",
    "            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],\n",
    "            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],\n",
    "            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],\n",
    "            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],\n",
    "            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],\n",
    "            [102, 255, 0], [92, 0, 255]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
